{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00874af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a Flask application, integrate YOLO object detection model in the application\n",
    "\n",
    "#Need to get video source,coordinates of the region from API call in Flask\n",
    "#Need to have two regions,one where person must be detected and in another region only car or two wheelers must be detected\n",
    "#Have left side of the video for person detection and right side for vehicles detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fc1a75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Kali/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2024-10-14 Python-3.11.5 torch-2.4.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:5000\n",
      " * Running on http://192.168.41.95:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [17/Oct/2024 18:41:06] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [17/Oct/2024 18:41:06] \"GET /favicon.ico HTTP/1.1\" 404 -\n",
      "127.0.0.1 - - [17/Oct/2024 18:42:43] \"POST /detect HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import warnings\n",
    "import torch\n",
    "from flask import Flask, request, jsonify, Response\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load YOLOv5 model from ultralytics\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
    "\n",
    "# Set detection classes for YOLO (0: 'Person', 2: 'car', 3: 'Two Wheelers')\n",
    "PERSON_CLASS = 0\n",
    "VEHICLE_CLASSES = [2, 3]  # Car and Two Wheelers\n",
    "\n",
    "def detect_objects(frame, model, region, classes_to_detect):\n",
    "    \n",
    "    x1, y1, x2, y2 = region\n",
    "    sub_frame = frame[y1:y2, x1:x2]  # Crop the region\n",
    "    \n",
    "    # Run YOLO detection\n",
    "    results = model(sub_frame)\n",
    "    \n",
    "    # Filter by classes\n",
    "    detected = results.xyxy[0].cpu().numpy()\n",
    "    for det in detected:\n",
    "        xmin, ymin, xmax, ymax, conf, cls = det\n",
    "        if int(cls) in classes_to_detect:\n",
    "            # Draw bounding boxes on the original frame (adjusting for region offset)\n",
    "            cv2.rectangle(frame, (int(xmin) + x1, int(ymin) + y1), (int(xmax) + x1, int(ymax) + y1), (0, 255, 0), 2)\n",
    "            label = model.names[int(cls)]\n",
    "            cv2.putText(frame, f'{label} {conf:.2f}', (int(xmin) + x1, int(ymin) + y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "    return frame\n",
    "\n",
    "def process_video(video_source, left_region, right_region):\n",
    "    \n",
    "    cap = cv2.VideoCapture(video_source)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        height, width, _ = frame.shape\n",
    "        # Split frame into left and right regions\n",
    "        frame = detect_objects(frame, model, left_region, [PERSON_CLASS])\n",
    "        frame = detect_objects(frame, model, right_region, VEHICLE_CLASSES)\n",
    "        \n",
    "        # Encode the frame to JPEG\n",
    "        _, buffer = cv2.imencode('.jpg', frame)\n",
    "        frame_bytes = buffer.tobytes()\n",
    "        \n",
    "        # Yield the frame in an HTTP response\n",
    "        yield (b'--frame\\r\\n' b'Content-Type: image/jpeg\\r\\n\\r\\n' + frame_bytes + b'\\r\\n')\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "@app.route('/detect', methods=['POST'])\n",
    "def detect():\n",
    "    \n",
    "    data = request.json\n",
    "    video_source = data['video_source']  # Corrected to match the key in the cURL request\n",
    "    left_region = data['left_region']  # Format: [x1, y1, x2, y2]\n",
    "    right_region = data['right_region']  # Format: [x1, y1, x2, y2]\n",
    "    \n",
    "    return Response(process_video(video_source, left_region, right_region), mimetype='multipart/x-mixed-replace; boundary=frame')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return \"YOLO Flask API is running. Use /detect endpoint for object detection.\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Run the Flask app\n",
    "    app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc9dd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST -H \"Content-Type: application/json\" -d \"{\\\"video_source\\\": \\\"C:\\\\\\\\Users\\\\\\\\Kali\\\\\\\\Downloads\\\\\\\\WhatsApp Video Caliber.mp4\\\", \\\"left_region\\\": [0, 0, 1920, 2160], \\\"right_region\\\": [1920, 0, 3840, 1920]}\" http://127.0.0.1:5000/detect --output \"C:\\Users\\Kali\\Downloads\\Caliber_Output\\output_video.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bec4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video Resolution: 3840x2160 pixels\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "video_source = r\"C:\\Users\\Kali\\Downloads\\WhatsApp Video Caliber.mp4\"\n",
    "cap = cv2.VideoCapture(video_source)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"NOt Opened\")\n",
    "else:\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    print(f'Video Resolution: {width}x{height} pixels')\n",
    "\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da53dd5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
